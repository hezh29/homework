# 人工智能伦理问题

近几年，人工智能在全世界都取得了巨大的进展。甚至有人预测20年后智能机器人的数量将从质量到数量全面赶超人类。但是，人工智能同样也带来了许多伦理问题。

## 算法歧视

由于算法或者数据的问题，人工智能可能会对某些人群有歧视。

>2015年芝加哥法院使用的一个犯罪风险评估算法COMPAS被证明对黑人造成了系统性歧视。如果一个黑人一旦犯了罪，他就更有可能被这个系统错误地标记为具有高犯罪风险，从而被法官判处更长的刑期。美国卡内基梅隆大学的一项研究显示，谷歌的广告系统可能存在性别歧视。在推送高收入工作招聘信息时，男性比女性收到推送的频率高得多。哈佛大学的研究也指出，“查询被逮捕记录”的广告会更加频繁地找上黑人。美国联邦贸易委员会在调查中发现广告商更倾向于将高息贷款信息展示给低收入群体看。  
作者：苏令银   
来源：中国社会科学网-中国社会科学报   
原文：http://www.cssn.cn/zx/bwyc/201710/t20171010_3662363_1.shtml

>“互动偏见”是指用户因为自己与算法的互动方式，而使算法产生的偏见。当机器被设定向周围环境学习时，它们不能决定要保留或者丢弃哪些数据、什么是对的或错的。相反地，它们只能使用提供给它们的数据——不论是好的、坏的，还是丑的，都只能依据此基础做出判断。前面提到的微软(Microsoft)聊天机器人Tay便是这类偏见的一个例子，它因为受到一个网络聊天社群的影响，开始变得有种族歧视了。  
“潜意识偏见”是指算法将错误的观念，与种族和性别等因素连结起来。例如，当搜寻一位医生的照片时，人工智能会先呈现男性医生的图片，而非女性医师，反之亦然，当搜寻护士的时候，也会发生类似的情况。  
“选择偏见”是指因数据而影响的算法，导致过于放大某一族群或群组，从而使该算法对其有利，而代价是牺牲其他群体。以员工招募为例，如果人工智能被训练成只辨识男性的履历，那么女性求职者在申请过程中，就很难成功。  
“数据导向的偏见”是指用来训练算法的原始数据已经存在偏见了。机器就像孩子一样：他们不会质疑所接收到的数据，只是单纯地寻找其中的模式。如果数据一开始就被扭曲，那么其输出的结果，也将会反映出这一点。  
最后一种是“确认偏见”，这和数据导向的偏见类似，它会偏向那些先入为主的信息，这类偏见影响人们如何收集信息，以及如何解读信息。例如，如果你觉得在8月份出生的人比其他月份出生的人更有创意，那么就会倾向于搜寻强化这种想法的数据。  
作者：Francisco Socal  
来源：智谷   
原文：http://zhigu.news.cn/2018-03/22/c_129834997.htm

## 个人隐私问题

人工智能带来的隐私问题也是不得不重视的。

>**数据采集中的隐私侵犯**  
随着各类AI智能设备的广泛使用，智能系统不仅能通过指纹、心跳等生理特征来辨别身份，还能根据不同人的行为喜好自动调节灯光、室内温度、播放音乐，甚至能通过睡眠时间、锻炼情况、饮食习惯以及体征变化等来判断身体是否健康。然而，这些智能技术的使用就意味着智能系统掌握了个人的大量信息，甚至比自己更了解自己。这些数据如果使用得当，可以提升人类的生活质量，但如果出于商业目的非法使用某些私人信息，就会造成隐私侵犯。  
**云计算中的隐私风险**  
因为云计算技术使用便捷、成本低廉，提供了基于共享池实现按需式资源使用的模式，许多公司和政府组织开始将AI大数据存储至云上。将隐私信息存储至云端后，这些信息就容易遭到各种威胁和攻击。由于人工智能系统普遍对计算能力要求较高，目前在许多人工智能应用中，云计算已经被配置为主要架构，因此在开发该类智能应用时，云端隐私保护也是人们需要考虑的问题。  
**知识抽取中的隐私问题**  
由数据到知识的抽取是人工智能的重要能力，知识抽取工具正在变得越来越强大，无数个看似不相关的数据片段可能被整合在一起，识别出个人行为特征甚至性格特征。例如，只要将网站浏览记录、聊天内容、购物过程和其他各类别记录数据组合在一起，就可以勾勒出某人的行为轨迹，并可分析出个人偏好和行为习惯，从而进一步预测出消费者的潜在需求，商家可提前为消费者提供必要的信息、产品或服务。但是，这些个性化定制过程又伴随着对个人隐私的发现和曝光，如何规范隐私保护是需要与技术应用同步考虑的一个问题。  
作者：shopeach科技频道  
来源：shopeach   
原文：https://www.shopeach.com/post/2088

## 责任与安全

>霍金、施密特等之前都警惕强人工智能或者超人工智能可能威胁人类生存。但在具体层面，AI安全包括行为安全和人类控制。从阿西莫夫提出的机器人三定律到2017年阿西洛马会议提出的23条人工智能原则，AI安全始终是人们关注的一个重点，美国、英国、欧盟等都在着力推进对自动驾驶汽车、智能机器人的安全监管。此外，安全往往与责任相伴。如果自动驾驶汽车、智能机器人造成人身、财产损害，谁来承担责任？如果按照现有的法律责任规则，因为系统是自主性很强的，它的开发者是难以预测的，包括黑箱的存在，很难解释事故的原因，未来可能会产生责任鸿沟。  
作者：曹建峰(Jeff Cao)
来源：知乎  
原文：https://zhuanlan.zhihu.com/p/31079090

## 最后

人工智能带来的伦理问题，上面只列举了部分。这些伦理问题是社会不得不面对与解决的。